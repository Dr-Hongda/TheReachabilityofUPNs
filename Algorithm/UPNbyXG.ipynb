{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python3.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from baggingPU import BaggingClassifierPU\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cm(cm, labels, hide_zeroes=False, hide_diagonal=False, hide_threshold=None):\n",
    "    columnwidth = max([len(x) for x in labels]) + 4\n",
    "    empty_cell = \" \" * columnwidth\n",
    "    print(\"    \" + empty_cell, end=' ')\n",
    "    for label in labels:\n",
    "        print(\"%{0}s\".format(columnwidth) % 'pred_' + label, end=\" \")\n",
    "    print()\n",
    "\n",
    "    for i, label1 in enumerate(labels):\n",
    "        print(\"    %{0}s\".format(columnwidth) % 'true_' + label1, end=\" \")\n",
    "        for j in range(len(labels)):\n",
    "            cell = \"%{0}.1f\".format(columnwidth) % cm[i, j]\n",
    "            if hide_zeroes:\n",
    "                cell = cell if float(cm[i, j]) != 0 else empty_cell\n",
    "            if hide_diagonal:\n",
    "                cell = cell if i != j else empty_cell\n",
    "            if hide_threshold:\n",
    "                cell = cell if cm[i, j] > hide_threshold else empty_cell\n",
    "            if cell:\n",
    "                print(cell, end=\" \")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    10000\n",
      "1    10000\n",
      "Name: label, dtype: int64\n",
      "Has null values False\n"
     ]
    }
   ],
   "source": [
    "#df_raw = pd.read_csv('../data/w-dependence.csv')\n",
    "\n",
    "# df_raw = pd.read_csv('../data/3x+1.csv')\n",
    "df_raw = pd.read_csv('../data/1place-independence.csv')\n",
    "\n",
    "#df_raw = pd.read_csv('../data/w-related.csv')\n",
    "\n",
    "\n",
    "df_raw['label'] = df_raw['label'].astype(\"int\")\n",
    "print(df_raw.label.value_counts())\n",
    "print('Has null values', df_raw.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   p1  p2  p3  p4  label\n",
       "0   1   0   0   0      1\n",
       "1   0   1   1   0      1\n",
       "2   1   0   1   0      1\n",
       "3   0   0   0   1      1\n",
       "4   0   1   2   0      1\n",
       "5   1   0   2   0      1\n",
       "6   0   0   1   1      1\n",
       "7   0   1   3   0      1\n",
       "8   1   0   3   0      1\n",
       "9   0   0   2   1      1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000\n",
      "4000\n",
      "1    8077\n",
      "0    7923\n",
      "Name: label, dtype: int64\n",
      "Has null values False\n",
      "0    2077\n",
      "1    1923\n",
      "Name: label, dtype: int64\n",
      "Has null values False\n"
     ]
    }
   ],
   "source": [
    "x_data = df_raw.iloc[:,:-1]\n",
    "y_data = df_raw.iloc[:,-1]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=7)\n",
    "\n",
    "x_train_input = pd.concat([x_train,y_train],axis=1)\n",
    "x_test_input = pd.concat([x_test,y_test],axis=1)\n",
    "\n",
    "print(len(x_train_input))\n",
    "print(len(x_test_input))\n",
    "\n",
    "print(x_train_input.label.value_counts())\n",
    "print('Has null values', x_train_input.isnull().values.any())\n",
    "\n",
    "print(x_test_input.label.value_counts())\n",
    "print('Has null values', x_test_input.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>p4</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8118</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2705</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10171</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2141</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9399</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3132</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12669</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2336</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18809</th>\n",
       "      <td>1457</td>\n",
       "      <td>3115</td>\n",
       "      <td>942</td>\n",
       "      <td>1111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13869</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1609</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3320</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1107</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14689</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1319</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13087</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2692</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15992</th>\n",
       "      <td>515</td>\n",
       "      <td>833</td>\n",
       "      <td>2507</td>\n",
       "      <td>1884</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         p1    p2    p3    p4  label\n",
       "8118      0     0  2705     1      1\n",
       "10171     0     0  2141     0      0\n",
       "9399      0     0  3132     1      1\n",
       "12669     1     1  2336     0      0\n",
       "18809  1457  3115   942  1111      0\n",
       "13869     0     0  1609     0      0\n",
       "3320      1     0  1107     0      1\n",
       "14689     1     1  1319     0      0\n",
       "13087     1     1  2692     1      0\n",
       "15992   515   833  2507  1884      0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_input.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = x_train_input.copy()\n",
    "\n",
    "NON_LBL = [c for c in df.columns if c != 'label']\n",
    "X = df[NON_LBL]\n",
    "y = df['label']\n",
    "\n",
    "y_orig = y.copy()\n",
    "\n",
    "hidden_size = 3000\n",
    "y.loc[\n",
    "    np.random.choice(\n",
    "        y[y == 1].index, \n",
    "        replace = False, \n",
    "        size = hidden_size\n",
    "    )\n",
    "] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10923\n",
       "1     5077\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainning directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGboost model ...\n",
      "[15:43:59] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print('Training XGboost model ...')\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "model = xgb.XGBClassifier()\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- XGboost model ----\n",
      "                        pred_negative        pred_positive \n",
      "           true_negative       7922.0          1.0 \n",
      "           true_positive       1011.0       7066.0 \n",
      "None\n",
      "\n",
      "Precision:  0.9998584972406962\n",
      "Recall:  0.8748297635260617\n",
      "Accuracy:  0.93675\n",
      "f1_score:  0.9331748547279451\n"
     ]
    }
   ],
   "source": [
    "print('---- {} ----'.format('XGboost model'))\n",
    "print(print_cm(sklearn.metrics.confusion_matrix(y_orig, model.predict(X)), labels=['negative', 'positive']))\n",
    "print('')\n",
    "print('Precision: ', precision_score(y_orig, model.predict(X)))\n",
    "print('Recall: ', recall_score(y_orig, model.predict(X)))\n",
    "print('Accuracy: ', accuracy_score(y_orig, model.predict(X)))\n",
    "print('f1_score: ', f1_score(y_orig, model.predict(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training by bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training bagging classifier...\n",
      "Done!\n",
      "Time: 10.194356688996777\n"
     ]
    }
   ],
   "source": [
    "print('Training bagging classifier...')\n",
    "\n",
    "pu_start = time.perf_counter()\n",
    "model = BaggingClassifierPU(xgb.XGBClassifier(), \n",
    "                         n_jobs = -1, \n",
    "                         max_samples = sum(y)  \n",
    "                        )\n",
    "model.fit(X, y)\n",
    "model.predict(x_data)\n",
    "pu_end = time.perf_counter()\n",
    "print('Done!')\n",
    "print('Time:', pu_end - pu_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- PU Bagging ----\n",
      "                        pred_negative        pred_positive \n",
      "           true_negative       7922.0          1.0 \n",
      "           true_positive         24.0       8053.0 \n",
      "None\n",
      "\n",
      "Precision:  0.9998758380928731\n",
      "Recall:  0.9970285997276216\n",
      "Accuracy:  0.9984375\n",
      "f1_score:  0.9984501890769325\n"
     ]
    }
   ],
   "source": [
    "#train data\n",
    "print('---- {} ----'.format('PU Bagging'))\n",
    "print(print_cm(sklearn.metrics.confusion_matrix(y_orig, model.predict(X)), labels=['negative', 'positive']))\n",
    "print('')\n",
    "print('Precision: ', precision_score(y_orig, model.predict(X)))\n",
    "print('Recall: ', recall_score(y_orig, model.predict(X)))\n",
    "print('Accuracy: ', accuracy_score(y_orig, model.predict(X)))\n",
    "print('f1_score: ', f1_score(y_orig, model.predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Negtive:\n",
      "      p1  p2    p3  p4\n",
      "173    1   0    58   0\n",
      "116    1   0    39   0\n",
      "9866   1   0  3289   0\n",
      "123    0   0    40   1\n",
      "109    0   1    37   0\n",
      "9872   1   0  3291   0\n",
      "9869   1   0  3290   0\n",
      "110    1   0    37   0\n",
      "112    0   1    38   0\n",
      "9863   1   0  3288   0\n",
      "152    1   0    51   0\n",
      "8929   0   1  2977   0\n",
      "8940   0   0  2979   1\n",
      "9117   0   0  3038   1\n",
      "179    1   0    60   0\n",
      "146    1   0    49   0\n",
      "8935   0   1  2979   0\n",
      "170    1   0    57   0\n",
      "8932   0   1  2978   0\n",
      "8934   0   0  2977   1\n",
      "9860   1   0  3287   0\n",
      "120    0   0    39   1\n",
      "176    1   0    59   0\n",
      "143    1   0    48   0\n",
      "False Positive:\n",
      "       p1  p2  p3  p4\n",
      "10002   0   1   0   0\n"
     ]
    }
   ],
   "source": [
    "#print wrong predictions\n",
    "y_pre = model.predict(X)\n",
    "y_orig_index = y_orig.index.tolist()\n",
    "\n",
    "FN_index = []\n",
    "FT_index = []\n",
    "\n",
    "for i in range(len(y_orig)):\n",
    "    if y_orig.iloc[i] == 1 and y_pre[i] == 0 :\n",
    "        FN_index.append(y_orig_index[i])\n",
    "    if y_orig.iloc[i] == 0 and y_pre[i] == 1 :\n",
    "        FT_index.append(y_orig_index[i])\n",
    "        \n",
    "print(\"False Negtive:\")\n",
    "print(X.loc[FN_index])\n",
    "print(\"False Positive:\")\n",
    "print(X.loc[FT_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- PU Bagging ----\n",
      "                        pred_negative        pred_positive \n",
      "           true_negative       2077.0          0.0 \n",
      "           true_positive          8.0       1915.0 \n",
      "None\n",
      "\n",
      "Precision:  1.0\n",
      "Recall:  0.9958398335933437\n",
      "Accuracy:  0.998\n",
      "f1_score:  0.9979155810317873\n"
     ]
    }
   ],
   "source": [
    "#test data\n",
    "print('---- {} ----'.format('PU Bagging'))\n",
    "print(print_cm(sklearn.metrics.confusion_matrix(y_test, model.predict(x_test)), labels=['negative', 'positive']))\n",
    "print('')\n",
    "print('Precision: ', precision_score(y_test, model.predict(x_test)))\n",
    "print('Recall: ', recall_score(y_test, model.predict(x_test)))\n",
    "print('Accuracy: ', accuracy_score(y_test, model.predict(x_test)))\n",
    "print('f1_score: ', f1_score(y_test, model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Negtive:\n",
      "      p1  p2    p3  p4\n",
      "9111   0   0  3036   1\n",
      "149    1   0    50   0\n",
      "113    1   0    38   0\n",
      "117    0   0    38   1\n",
      "9114   0   0  3037   1\n",
      "115    0   1    39   0\n",
      "8937   0   0  2978   1\n",
      "9857   1   0  3286   0\n",
      "False Positive:\n",
      "Empty DataFrame\n",
      "Columns: [p1, p2, p3, p4]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#print wrong predictions\n",
    "y_test_pre = model.predict(x_test)\n",
    "y_test_index = y_test.index.tolist()\n",
    "\n",
    "FN_test_index = []\n",
    "FT_test_index = []\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    if y_test.iloc[i] == 1 and y_test_pre[i] == 0 :\n",
    "        FN_test_index.append(y_test_index[i])\n",
    "    if y_test.iloc[i] == 0 and y_test_pre[i] == 1 :\n",
    "        FT_test_index.append(y_test_index[i])\n",
    "\n",
    "print(\"False Negtive:\")\n",
    "print(x_test.loc[FN_test_index])\n",
    "print(\"False Positive:\")\n",
    "print(x_test.loc[FT_test_index])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
