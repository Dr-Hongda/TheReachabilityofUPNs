{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from baggingPU import BaggingClassifierPU\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cm(cm, labels, hide_zeroes=False, hide_diagonal=False, hide_threshold=None):\n",
    "    columnwidth = max([len(x) for x in labels]) + 4\n",
    "    empty_cell = \" \" * columnwidth\n",
    "    print(\"    \" + empty_cell, end=' ')\n",
    "    for label in labels:\n",
    "        print(\"%{0}s\".format(columnwidth) % 'pred_' + label, end=\" \")\n",
    "    print()\n",
    "\n",
    "    for i, label1 in enumerate(labels):\n",
    "        print(\"    %{0}s\".format(columnwidth) % 'true_' + label1, end=\" \")\n",
    "        for j in range(len(labels)):\n",
    "            cell = \"%{0}.1f\".format(columnwidth) % cm[i, j]\n",
    "            if hide_zeroes:\n",
    "                cell = cell if float(cm[i, j]) != 0 else empty_cell\n",
    "            if hide_diagonal:\n",
    "                cell = cell if i != j else empty_cell\n",
    "            if hide_threshold:\n",
    "                cell = cell if cm[i, j] > hide_threshold else empty_cell\n",
    "            if cell:\n",
    "                print(cell, end=\" \")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    10000\n",
      "0    10000\n",
      "Name: label, dtype: int64\n",
      "Has null values False\n"
     ]
    }
   ],
   "source": [
    "df_raw = pd.read_csv('../data/w-dependence.csv')\n",
    "\n",
    "#df_raw = pd.read_csv('../data/1place-dependence.csv')\n",
    "\n",
    "#df_raw = pd.read_csv('../data/w-related.csv')\n",
    "\n",
    "\n",
    "df_raw['label'] = df_raw['label'].astype(\"int\")\n",
    "print(df_raw.label.value_counts())\n",
    "print('Has null values', df_raw.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   p1  p2  p3  label\n",
       "0   0   0   1      1\n",
       "1   1   0   1      1\n",
       "2   0   1   1      1\n",
       "3   2   0   1      1\n",
       "4   1   1   1      1\n",
       "5   0   1   0      1\n",
       "6   0   2   1      1\n",
       "7   3   0   1      1\n",
       "8   2   1   1      1\n",
       "9   1   1   0      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      p1  p2  p3  label\n",
      "0      0   0   1      1\n",
      "1      1   0   1      1\n",
      "2      0   1   1      1\n",
      "3      2   0   1      1\n",
      "4      1   1   1      1\n",
      "...   ..  ..  ..    ...\n",
      "9995  52  47   0      1\n",
      "9996  52  48   1      1\n",
      "9997  51  48   0      1\n",
      "9998  51  49   1      1\n",
      "9999  50  49   0      1\n",
      "\n",
      "[10000 rows x 4 columns]\n",
      "p1    100\n",
      "p2     99\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_raw.iloc[:10000,:])\n",
    "df_max = np.amax(df_raw.iloc[:10000,[0,1]])\n",
    "print(df_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        p1   p2   p3  label\n",
      "10000   86  724  444      0\n",
      "10001  556  145   65      0\n",
      "10002  395  673   66      0\n",
      "10003  151  410  204      0\n",
      "10004  961  853  760      0\n",
      "...    ...  ...  ...    ...\n",
      "19995  300  764  197      0\n",
      "19996  123  206  636      0\n",
      "19997  756  279  632      0\n",
      "19998  675  960  101      0\n",
      "19999  480  640  168      0\n",
      "\n",
      "[10000 rows x 4 columns]\n",
      "p1    999\n",
      "p2    999\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_raw.iloc[10000:,:])\n",
    "print(np.amax(df_raw.iloc[10000:,[0,1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        p1   p2   p3  label\n",
      "10000   86  724  444      0\n",
      "10001  556  145   65      0\n",
      "10002  395  673   66      0\n",
      "10003  151  410  204      0\n",
      "10004  961  853  760      0\n",
      "...    ...  ...  ...    ...\n",
      "19995  300  764  197      0\n",
      "19996  123  206  636      0\n",
      "19997  756  279  632      0\n",
      "19998  675  960  101      0\n",
      "19999  480  640  168      0\n",
      "\n",
      "[10000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "neg_process = df_raw.iloc[10000:,:].copy()\n",
    "print(neg_process)\n",
    "\n",
    "for i in range(10000):\n",
    "    if neg_process.iloc[i,0] > df_max[0]:\n",
    "        neg_process.iloc[i,0]  = int(neg_process.iloc[i,0] / df_max[0])\n",
    "    if neg_process.iloc[i,1] > df_max[1]:\n",
    "        neg_process.iloc[i,1]  = int(neg_process.iloc[i,1] / df_max[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       p1  p2   p3  label\n",
      "10000  86   7  444      0\n",
      "10001   5   1   65      0\n",
      "10002   3   6   66      0\n",
      "10003   1   4  204      0\n",
      "10004   9   8  760      0\n",
      "...    ..  ..  ...    ...\n",
      "19995   3   7  197      0\n",
      "19996   1   2  636      0\n",
      "19997   7   2  632      0\n",
      "19998   6   9  101      0\n",
      "19999   4   6  168      0\n",
      "\n",
      "[9605 rows x 4 columns]\n",
      "p1       100\n",
      "p2        99\n",
      "p3       999\n",
      "label      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "neg_process.drop_duplicates(inplace=True)\n",
    "print(neg_process)\n",
    "print(np.amax(neg_process))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       p1  p2   p3  label\n",
      "0       0   0    1      1\n",
      "1       1   0    1      1\n",
      "2       0   1    1      1\n",
      "3       2   0    1      1\n",
      "4       1   1    1      1\n",
      "...    ..  ..  ...    ...\n",
      "19995   3   7  197      0\n",
      "19996   1   2  636      0\n",
      "19997   7   2  632      0\n",
      "19998   6   9  101      0\n",
      "19999   4   6  168      0\n",
      "\n",
      "[19605 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "df_process = pd.concat([df_raw.iloc[:10000,:], neg_process])\n",
    "print(df_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = df_process.iloc[:,:-1]\n",
    "y_data = df_process.iloc[:,-1]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000\n",
      "4000\n",
      "1    8077\n",
      "0    7923\n",
      "Name: label, dtype: int64\n",
      "Has null values False\n",
      "0    2077\n",
      "1    1923\n",
      "Name: label, dtype: int64\n",
      "Has null values False\n"
     ]
    }
   ],
   "source": [
    "x_train_input = pd.concat([x_train.iloc[:,:], y_train],axis=1)\n",
    "x_test_input = pd.concat([x_test.iloc[:,:],y_test],axis=1)\n",
    "\n",
    "print(len(x_train_input))\n",
    "print(len(x_test_input))\n",
    "\n",
    "print(x_train_input.label.value_counts())\n",
    "print('Has null values', x_train_input.isnull().values.any())\n",
    "\n",
    "print(x_test_input.label.value_counts())\n",
    "print('Has null values', x_test_input.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8118</th>\n",
       "      <td>36</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10171</th>\n",
       "      <td>955</td>\n",
       "      <td>144</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9399</th>\n",
       "      <td>53</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12669</th>\n",
       "      <td>671</td>\n",
       "      <td>887</td>\n",
       "      <td>315</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18809</th>\n",
       "      <td>118</td>\n",
       "      <td>877</td>\n",
       "      <td>702</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13869</th>\n",
       "      <td>403</td>\n",
       "      <td>912</td>\n",
       "      <td>555</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3320</th>\n",
       "      <td>51</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14689</th>\n",
       "      <td>884</td>\n",
       "      <td>235</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13087</th>\n",
       "      <td>17</td>\n",
       "      <td>244</td>\n",
       "      <td>215</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15992</th>\n",
       "      <td>709</td>\n",
       "      <td>14</td>\n",
       "      <td>565</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        p1   p2   p3  label\n",
       "8118    36   54    1      1\n",
       "10171  955  144   14      0\n",
       "9399    53   43    0      1\n",
       "12669  671  887  315      0\n",
       "18809  118  877  702      0\n",
       "13869  403  912  555      0\n",
       "3320    51    7    1      1\n",
       "14689  884  235    9      0\n",
       "13087   17  244  215      0\n",
       "15992  709   14  565      0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_input.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "      <th>p3</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14356</th>\n",
       "      <td>56</td>\n",
       "      <td>136</td>\n",
       "      <td>763</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3439</th>\n",
       "      <td>50</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12153</th>\n",
       "      <td>23</td>\n",
       "      <td>213</td>\n",
       "      <td>534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15029</th>\n",
       "      <td>461</td>\n",
       "      <td>505</td>\n",
       "      <td>575</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18549</th>\n",
       "      <td>657</td>\n",
       "      <td>746</td>\n",
       "      <td>995</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15762</th>\n",
       "      <td>282</td>\n",
       "      <td>709</td>\n",
       "      <td>653</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12313</th>\n",
       "      <td>456</td>\n",
       "      <td>178</td>\n",
       "      <td>499</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16034</th>\n",
       "      <td>409</td>\n",
       "      <td>843</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11496</th>\n",
       "      <td>911</td>\n",
       "      <td>433</td>\n",
       "      <td>846</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5653</th>\n",
       "      <td>23</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        p1   p2   p3  label\n",
       "14356   56  136  763      0\n",
       "3439    50    8    0      1\n",
       "12153   23  213  534      0\n",
       "15029  461  505  575      0\n",
       "18549  657  746  995      0\n",
       "15762  282  709  653      0\n",
       "12313  456  178  499      0\n",
       "16034  409  843   59      0\n",
       "11496  911  433  846      0\n",
       "5653    23   51    0      1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_input.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13000\n"
     ]
    }
   ],
   "source": [
    "iter = 13000\n",
    "alllist = np.zeros([13000,4],dtype=np.int)\n",
    "\n",
    "a = np.random.choice(range(9,999),size=iter,replace=True)\n",
    "b = np.random.choice(range(0,999),size=iter,replace=True)\n",
    "c = np.random.choice(range(9,999),size=iter,replace=True)\n",
    "\n",
    "for idx in range(iter):  \n",
    "    alllist[idx][0] = a[idx]\n",
    "    alllist[idx][1] = b[idx]\n",
    "    alllist[idx][2] = c[idx]\n",
    "    alllist[idx][3] = 0\n",
    "unlabel = np.unique(np.array(alllist), axis = 0)\n",
    "\n",
    "print(len(unlabel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        p1   p2   p3  label\n",
      "0       44   24    1      1\n",
      "1       27   16    1      1\n",
      "2       34    5    0      1\n",
      "3       13   36    0      1\n",
      "4       47   25    0      1\n",
      "...    ...  ...  ...    ...\n",
      "15995  998  462  897      0\n",
      "15996  998  898  936      0\n",
      "15997  998  915  594      0\n",
      "15998  998  961  682      0\n",
      "15999  998  991  230      0\n",
      "\n",
      "[16000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "pos_list = np.random.randint(low=100, high=9999, size=3000).tolist()\n",
    "\n",
    "data_pos = df_process.iloc[pos_list,:]\n",
    "data_unl = pd.DataFrame(unlabel, columns=['p1','p2','p3','label'],)\n",
    "\n",
    "data =  pd.concat([data_pos, data_unl], axis = 0, ignore_index=True)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        p1   p2   p3\n",
      "0       44   24    1\n",
      "1       27   16    1\n",
      "2       34    5    0\n",
      "3       13   36    0\n",
      "4       47   25    0\n",
      "...    ...  ...  ...\n",
      "15995  998  462  897\n",
      "15996  998  898  936\n",
      "15997  998  915  594\n",
      "15998  998  961  682\n",
      "15999  998  991  230\n",
      "\n",
      "[16000 rows x 3 columns]\n",
      "0        1\n",
      "1        1\n",
      "2        1\n",
      "3        1\n",
      "4        1\n",
      "        ..\n",
      "15995    0\n",
      "15996    0\n",
      "15997    0\n",
      "15998    0\n",
      "15999    0\n",
      "Name: label, Length: 16000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = data.copy()\n",
    "\n",
    "X = df.iloc[:,:-1]\n",
    "y = df.iloc[:,-1]\n",
    "\n",
    "y_orig = y.copy()\n",
    "\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    13000\n",
       "1     3000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainning directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGboost model ...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print('Training XGboost model ...')\n",
    "\n",
    "#import xgboost as xgb\n",
    "\n",
    "#model = xgb.XGBClassifier()\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "\n",
    "\n",
    "#from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#model = MLPClassifier(solver='adam', alpha=1e-5,hidden_layer_sizes=(1), random_state=1,max_iter=100000)\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- XGboost model ----\n",
      "                        pred_negative        pred_positive \n",
      "           true_negative       2076.0          1.0 \n",
      "           true_positive          0.0       1923.0 \n",
      "None\n",
      "\n",
      "Precision:  0.9994802494802495\n",
      "Recall:  1.0\n",
      "Accuracy:  0.99975\n",
      "f1_score:  0.9997400571874188\n"
     ]
    }
   ],
   "source": [
    "print('---- {} ----'.format('XGboost model'))\n",
    "print(print_cm(sklearn.metrics.confusion_matrix(y_test, model.predict(x_test_input.iloc[:,:-1])), labels=['negative', 'positive']))\n",
    "print('')\n",
    "print('Precision: ', precision_score(y_test, model.predict(x_test_input.iloc[:,:-1])))\n",
    "print('Recall: ', recall_score(y_test, model.predict(x_test_input.iloc[:,:-1])))\n",
    "print('Accuracy: ', accuracy_score(y_test, model.predict(x_test_input.iloc[:,:-1])))\n",
    "print('f1_score: ', f1_score(y_test, model.predict(x_test_input.iloc[:,:-1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training by bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#初始化多个分类器\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model1 = LogisticRegression()\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model2 = DecisionTreeClassifier()\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "model3 = MLPClassifier(solver='adam', alpha=1e-5,hidden_layer_sizes=(1), random_state=1,max_iter=100000)\n",
    "\n",
    "from sklearn import svm\n",
    "model4 = svm.LinearSVC()\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model5 = MultinomialNB()\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model6 = RandomForestClassifier(n_estimators = 50,n_jobs = -1)\n",
    "\n",
    "import xgboost as xgb\n",
    "model7 = xgb.XGBClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "predict_sum = np.zeros([len(y)],dtype=np.float32)\n",
    "print(predict_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9994503023337165\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (16000,) (20000,) (16000,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-da21fb1368cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mpredict_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (16000,) (20000,) (16000,) "
     ]
    }
   ],
   "source": [
    "flag = 0\n",
    "f1 = np.zeros([7],dtype=np.float32)\n",
    "\n",
    "model_list = [model1, model2, model3, model4, model5, model6, model7]\n",
    "\n",
    "for i,j in zip(model_list,range(7)):\n",
    "    model = BaggingClassifierPU(i,\n",
    "                         n_estimators = 50, \n",
    "                         n_jobs = -1, \n",
    "                         max_samples = sum(y)  \n",
    "                        )\n",
    "    model.fit(X,y)\n",
    "    print(f1_score(y_data, model.predict(x_data)))\n",
    "    predict_sum += model.predict(x_data)\n",
    "    f1[j] = f1_score(y_data, model.predict(x_data))\n",
    "\n",
    "print(f1)\n",
    "print(predict_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 0 0 0]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(x_data))\n",
    "print(type(model.predict(x_data)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5\n"
     ]
    }
   ],
   "source": [
    "threshold = len(model_list) / 2\n",
    "print(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "BaggingClassifierPU(base_estimator=LogisticRegression(), max_samples=3000,\n",
      "                    n_estimators=50, n_jobs=-1)\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(f1))\n",
    "\n",
    "best_model = BaggingClassifierPU(model_list[np.argmax(f1)],\n",
    "                         n_estimators = 50, \n",
    "                         n_jobs = -1, \n",
    "                         max_samples = sum(y)  \n",
    "                        )\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training bagging classifier...\n",
      "Done!\n",
      "Time: 0.9347040150023531\n"
     ]
    }
   ],
   "source": [
    "print('Training bagging classifier...')\n",
    "\n",
    "pu_start = time.perf_counter()\n",
    "model = BaggingClassifierPU(LogisticRegression(),\n",
    "                         n_estimators = 50, \n",
    "                         n_jobs = -1, \n",
    "                         max_samples = sum(y)  \n",
    "                        )\n",
    "model.fit(X, y)\n",
    "pu_end = time.perf_counter()\n",
    "print('Done!')\n",
    "print('Time:', pu_end - pu_start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- PU Bagging ----\n",
      "                        pred_negative        pred_positive \n",
      "           true_negative      12998.0          2.0 \n",
      "           true_positive          0.0       3000.0 \n",
      "None\n",
      "\n",
      "Precision:  0.9993337774816788\n",
      "Recall:  1.0\n",
      "Accuracy:  0.999875\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.ndarray' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-161-a49b2336591e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Recall: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_orig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_orig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f1_score: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_orig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
     ]
    }
   ],
   "source": [
    "#train data\n",
    "print('---- {} ----'.format('PU Bagging'))\n",
    "print(print_cm(sklearn.metrics.confusion_matrix(y_orig, model.predict(X)), labels=['negative', 'positive']))\n",
    "print('')\n",
    "print('Precision: ', precision_score(y_orig, model.predict(X)))\n",
    "print('Recall: ', recall_score(y_orig, model.predict(X)))\n",
    "print('Accuracy: ', accuracy_score(y_orig, model.predict(X)))\n",
    "print('f1_score: ', f1_score(y_orig, model.predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Negtive:\n",
      "Empty DataFrame\n",
      "Columns: [p1, p2, p3, label]\n",
      "Index: []\n",
      "False Positive:\n",
      "      p1  p2  p3  label\n",
      "3385  18  39   0      1\n"
     ]
    }
   ],
   "source": [
    "#print wrong predictions\n",
    "y_pre = model.predict(X)\n",
    "y_orig_index = y_orig.index.tolist()\n",
    "\n",
    "FN_index = []\n",
    "FT_index = []\n",
    "\n",
    "for i in range(len(y_orig)):\n",
    "    if y_orig.iloc[i] == 1 and y_pre[i] == 0 :\n",
    "        FN_index.append(y_orig_index[i])\n",
    "    if y_orig.iloc[i] == 0 and y_pre[i] == 1 :\n",
    "        FT_index.append(y_orig_index[i])\n",
    "        \n",
    "print(\"False Negtive:\")\n",
    "print(df_process.loc[FN_index])\n",
    "print(\"False Positive:\")\n",
    "print(df_process.loc[FT_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- PU Bagging ----\n",
      "                        pred_negative        pred_positive \n",
      "           true_negative       2075.0          2.0 \n",
      "           true_positive          0.0       1923.0 \n",
      "None\n",
      "\n",
      "Precision:  0.9989610389610389\n",
      "Recall:  1.0\n",
      "Accuracy:  0.9995\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.ndarray' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-160-91ea07fa1047>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Recall: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f1_score: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
     ]
    }
   ],
   "source": [
    "#test data\n",
    "print('---- {} ----'.format('PU Bagging'))\n",
    "print(print_cm(sklearn.metrics.confusion_matrix(y_test, model.predict(x_test_input.iloc[:,:-1])), labels=['negative', 'positive']))\n",
    "print('')\n",
    "print('Precision: ', precision_score(y_test, model.predict(x_test_input.iloc[:,:-1])))\n",
    "print('Recall: ', recall_score(y_test, model.predict(x_test_input.iloc[:,:-1])))\n",
    "print('Accuracy: ', accuracy_score(y_test, model.predict(x_test_input.iloc[:,:-1])))\n",
    "print('f1_score: ', f1_score(y_test, model.predict(x_test_input.iloc[:,:-1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Negtive:\n",
      "Empty DataFrame\n",
      "Columns: [p1, p2, p3, label]\n",
      "Index: []\n",
      "False Positive:\n",
      "       p1  p2  p3  label\n",
      "14102  17  33  28      0\n",
      "17305  46   5  11      0\n"
     ]
    }
   ],
   "source": [
    "#print wrong predictions\n",
    "y_test_pre = model.predict(x_test_input.iloc[:,:-1])\n",
    "y_test_index = y_test.index.tolist()\n",
    "\n",
    "FN_test_index = []\n",
    "FT_test_index = []\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    if y_test.iloc[i] == 1 and y_test_pre[i] == 0 :\n",
    "        FN_test_index.append(y_test_index[i])\n",
    "    if y_test.iloc[i] == 0 and y_test_pre[i] == 1 :\n",
    "        FT_test_index.append(y_test_index[i])\n",
    "\n",
    "print(\"False Negtive:\")\n",
    "print(df_process.loc[FN_test_index])\n",
    "print(\"False Positive:\")\n",
    "print(df_process.loc[FT_test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        p1   p2   p3\n",
      "0        0    0    1\n",
      "1        1    0    1\n",
      "2        0    1    1\n",
      "3        2    0    1\n",
      "4        1    1    1\n",
      "...    ...  ...  ...\n",
      "19995  300  764  197\n",
      "19996  123  206  636\n",
      "19997  756  279  632\n",
      "19998  675  960  101\n",
      "19999  480  640  168\n",
      "\n",
      "[20000 rows x 3 columns]\n",
      "[1 1 1 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "orig_data = df_process.iloc[:,:-1].copy()\n",
    "orig_label = model.predict(orig_data)\n",
    "\n",
    "print(orig_data)\n",
    "print(orig_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaggingClassifierPU(base_estimator=XGBClassifier(base_score=None, booster=None,\n",
      "                                                 colsample_bylevel=None,\n",
      "                                                 colsample_bynode=None,\n",
      "                                                 colsample_bytree=None,\n",
      "                                                 gamma=None, gpu_id=None,\n",
      "                                                 importance_type='gain',\n",
      "                                                 interaction_constraints=None,\n",
      "                                                 learning_rate=None,\n",
      "                                                 max_delta_step=None,\n",
      "                                                 max_depth=None,\n",
      "                                                 min_child_weight=None,\n",
      "                                                 missing=nan,\n",
      "                                                 monotone_constraints=None,\n",
      "                                                 n_estimators=100, n_jobs=None,\n",
      "                                                 num_parallel_tree=None,\n",
      "                                                 random_state=None,\n",
      "                                                 reg_alpha=None,\n",
      "                                                 reg_lambda=None,\n",
      "                                                 scale_pos_weight=None,\n",
      "                                                 subsample=None,\n",
      "                                                 tree_method=None,\n",
      "                                                 validate_parameters=None,\n",
      "                                                 verbosity=None),\n",
      "                    max_samples=3000, n_estimators=50, n_jobs=-1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaggingClassifierPU(base_estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                                 colsample_bylevel=None,\n",
       "                                                 colsample_bynode=None,\n",
       "                                                 colsample_bytree=None,\n",
       "                                                 gamma=None, gpu_id=None,\n",
       "                                                 importance_type='gain',\n",
       "                                                 interaction_constraints=None,\n",
       "                                                 learning_rate=None,\n",
       "                                                 max_delta_step=None,\n",
       "                                                 max_depth=None,\n",
       "                                                 min_child_weight=None,\n",
       "                                                 missing=nan,\n",
       "                                                 monotone_constraints=None,\n",
       "                                                 n_estimators=100, n_jobs=None,\n",
       "                                                 num_parallel_tree=None,\n",
       "                                                 random_state=None,\n",
       "                                                 reg_alpha=None,\n",
       "                                                 reg_lambda=None,\n",
       "                                                 scale_pos_weight=None,\n",
       "                                                 subsample=None,\n",
       "                                                 tree_method=None,\n",
       "                                                 validate_parameters=None,\n",
       "                                                 verbosity=None),\n",
       "                    max_samples=3000, n_estimators=50, n_jobs=-1)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "model = BaggingClassifierPU(xgb.XGBClassifier(),\n",
    "                         n_estimators = 50, \n",
    "                         n_jobs = -1, \n",
    "                         max_samples = sum(y)  \n",
    "                        )\n",
    "print(model)\n",
    "model.fit(orig_data, orig_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "======\n",
      "         p1    p2   p3\n",
      "4712   1064  1014    1\n",
      "9561   1075  1031    0\n",
      "7382   1055  1040    1\n",
      "4880   1050  1029    1\n",
      "4935   1022  1056    0\n",
      "...     ...   ...  ...\n",
      "10830  1686  1258  309\n",
      "11607  1884  1839  157\n",
      "15843  1269  1893  529\n",
      "16876  1417  1372  960\n",
      "16579  1858  1831  485\n",
      "\n",
      "[4000 rows x 3 columns]\n",
      "---- 1 ----\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "Accuracy:  1.0\n",
      "f1_score:  1.0\n",
      "20\n",
      "======\n",
      "         p1    p2   p3\n",
      "8422   1078  1037    1\n",
      "3845   1041  1043    0\n",
      "2129   1027  1041    0\n",
      "8683   1040  1075    0\n",
      "1755   1036  1028    0\n",
      "...     ...   ...  ...\n",
      "17381  2005  1945  725\n",
      "18423  1140  1571  218\n",
      "18651  1021  1966  646\n",
      "16191  1035  1088  863\n",
      "13421  1020  1767  854\n",
      "\n",
      "[4000 rows x 3 columns]\n",
      "---- 2 ----\n",
      "Precision:  1.0\n",
      "Recall:  1.0\n",
      "Accuracy:  1.0\n",
      "f1_score:  1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-d8ab7d8e91e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0morig_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0morig_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../result/w_dependence_unknown_processdata_result.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/ReachabilityofUnboundedPN/baggingPU.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/ReachabilityofUnboundedPN/baggingPU.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, max_samples, max_depth, sample_weight)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moob_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_oob_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/ReachabilityofUnboundedPN/baggingPU.py\u001b[0m in \u001b[0;36m_set_oob_score\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         for estimator, samples, features in zip(self.estimators_,\n\u001b[0;32m--> 376\u001b[0;31m                                                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_samples_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m                                                 self.estimators_features_):\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/ReachabilityofUnboundedPN/baggingPU.py\u001b[0m in \u001b[0;36mestimators_samples_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mestimators_samples_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0msample_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_indices\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_estimators_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_to_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0msample_masks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/ReachabilityofUnboundedPN/baggingPU.py\u001b[0m in \u001b[0;36m_get_estimators_indices\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0miP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpair\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m             \u001b[0miU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpair\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/ReachabilityofUnboundedPN/baggingPU.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0miP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpair\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m             \u001b[0miU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpair\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#verification\n",
    "import random\n",
    "\n",
    "place_max = max(np.amax(df_process.iloc[:10000, [0, 1]]))  #w_dependence\n",
    "name1 = ['min', 'max', 'Precision', 'Recall', 'Accuracy', 'f1_score']\n",
    "test = pd.DataFrame(columns=name1)\n",
    "\n",
    "for i in range(1, 100):\n",
    "    \n",
    "    '''\n",
    "    flag = int((0.1 * i) * place_max)\n",
    "    print(flag)\n",
    "    temp_data = df_process.iloc[(10000 - int(0.1 * place_max)) : (10000 + int(0.1 * place_max)), : -1].copy()\n",
    "    temp_label = df_process.iloc[(10000 - int(0.1 * place_max)) : (10000 + int(0.1 * place_max)), -1].copy()\n",
    "    temp_data.iloc[:, 0] = temp_data.iloc[:, 0] + flag + 1\n",
    "    temp_data.iloc[:, 1] = temp_data.iloc[:, 1] + flag + 1\n",
    "    '''\n",
    "    \n",
    "    pos_list = np.random.randint(low=100, high=9999, size=2000).tolist()\n",
    "    neg_list = np.random.randint(low=10000, high=19000, size=2000).tolist()\n",
    "    all_list = pos_list + neg_list\n",
    "    \n",
    "    flag1 = int((0.1 * (i - 1)) * place_max)\n",
    "    flag2 = int((0.1 * i) * place_max)\n",
    "    print(flag2)\n",
    "    \n",
    "    temp_data = df_process.iloc[all_list, : -1].copy()\n",
    "    temp_label = df_process.iloc[all_list, -1].copy()\n",
    "    \n",
    "    temp_data.iloc[:, 0] = temp_data.iloc[:, 0] + random.randint((df_max[0] + flag1 + 1), ((df_max[0] + flag2 + 1)))\n",
    "    temp_data.iloc[:, 1] = temp_data.iloc[:, 1] + random.randint((df_max[1] + flag1 + 1), ((df_max[1] + flag2 + 1)))\n",
    "\n",
    "    \n",
    "    print('======')\n",
    "    print(temp_data.iloc[:, :])\n",
    "\n",
    "    temp_max = max(np.amax(temp_data.iloc[:, [0, 1]]))\n",
    "    temp_min = min(np.amin(temp_data.iloc[:, [0, 1]]))\n",
    "\n",
    "    print('---- {} ----'.format(i))\n",
    "    print('Precision: ', precision_score(temp_label, model.predict(temp_data)))\n",
    "    print('Recall: ', recall_score(temp_label, model.predict(temp_data)))\n",
    "    print('Accuracy: ', accuracy_score(temp_label, model.predict(temp_data)))\n",
    "    print('f1_score: ', f1_score(temp_label, model.predict(temp_data)))\n",
    "\n",
    "    test.loc[i] = [  temp_min, temp_max,\n",
    "                        precision_score(temp_label, model.predict(temp_data)),\n",
    "                        recall_score(temp_label, model.predict(temp_data)),\n",
    "                        accuracy_score(temp_label, model.predict(temp_data)),\n",
    "                        f1_score(temp_label, model.predict(temp_data))\n",
    "                        ]\n",
    "    \n",
    "    orig_data = pd.concat([orig_data, temp_data], ignore_index=True)\n",
    "    orig_label = pd.Series(orig_label.tolist() + model.predict(temp_data).tolist())\n",
    "\n",
    "    model.fit(orig_data,orig_label)\n",
    "\n",
    "test.to_csv('../result/w_dependence_unknown_processdata_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
